//! High-performance collection types optimized for computational geometry operations.
//!
//! This module provides centralized type aliases for performance-critical data structures
//! used throughout the delaunay triangulation library. These aliases allow for easy
//! future optimization and maintenance by providing a single location to change
//! the underlying implementation.
//!
//! # Performance Rationale
//!
//! The type aliases in this module are optimized based on the specific usage patterns
//! in computational geometry algorithms:
//!
//! ## Hash-based Collections
//!
//! - **FastHashMap/FastHashSet**: Uses `FastHasher`, a non-cryptographic hasher
//!   that is 2-3x faster than SipHash for trusted data. Perfect for internal data
//!   where collision resistance against adversarial input is not required.
//!
//! ### ⚠️ Security Warning: DoS Resistance
//!
//! **The hasher used in these collections is NOT DoS-resistant.** It should only be
//! used with trusted input data. Do not use `FastHashMap` or `FastHashSet` with
//! attacker-controlled keys, as this could lead to hash collision attacks that
//! degrade performance to O(n) worst-case behavior.
//!
//! **Safe usage patterns:**
//! - Internal geometric computations with generated/computed keys
//! - Trusted coordinate data from known sources
//! - UUID-based keys generated by the library itself
//!
//! **Unsafe usage patterns:**
//! - Processing untrusted coordinate data from external sources
//! - Using user-provided keys without validation
//! - Network-facing applications with external input
//!
//! ## Small Collections
//!
//! - **SmallVec**: Uses stack allocation for small collections, avoiding heap
//!   allocations for the common case where collections remain small. This is
//!   particularly effective for:
//!   - Vertex neighbor lists (typically D+1 neighbors)
//!   - Facet-to-cell mappings (typically 1-2 cells per facet)
//!   - Temporary collections during geometric operations
//!
//! # Usage Patterns
//!
//! The size parameters for SmallVec are chosen based on empirical analysis of
//! typical triangulation patterns:
//!
//! - **2 elements**: Facet sharing (boundary facets = 1 cell, interior facets = 2 cells)
//! - **4 elements**: Small temporary collections during geometric operations
//! - **8 elements**: Vertex degrees and cell neighbor counts in typical triangulations
//! - **16 elements**: Larger temporary buffers for batch operations
//!
//! # Future Optimization
//!
//! This centralized approach allows for easy experimentation with different
//! high-performance data structures:
//! - Alternative hash functions (ahash, seahash)
//! - Specialized geometric data structures
//! - SIMD-optimized containers
//! - Memory pool allocators
//!
//! # Examples
//!
//! ```rust
//! use delaunay::core::collections::{FastHashMap, SmallBuffer, FacetToCellsMap};
//!
//! // Use optimized HashMap for temporary mappings
//! let mut temp_map: FastHashMap<u64, usize> = FastHashMap::default();
//!
//! // Use stack-allocated buffer for small collections
//! let mut small_list: SmallBuffer<i32, 8> = SmallBuffer::new();
//! small_list.push(1);
//! small_list.push(2);
//!
//! // Use domain-specific optimized collections
//! let facet_map: FacetToCellsMap = FacetToCellsMap::default();
//! ```
//!
//! ## Phase 1 Migration: Key-Based Internal Operations
//!
//! Phase 1 of the UUID-to-Key migration provides optimized collections for internal operations:
//!
//! ```rust
//! use delaunay::core::collections::{CellKeySet, VertexKeySet, KeyBasedCellMap};
//! use delaunay::core::triangulation_data_structure::{CellKey, VertexKey};
//!
//! // Phase 1: Direct key-based collections for internal algorithms
//! let mut internal_cells: CellKeySet = CellKeySet::default();
//! let mut internal_vertices: VertexKeySet = VertexKeySet::default();
//! let mut key_mappings: KeyBasedCellMap<String> = KeyBasedCellMap::default();
//! ```

use rustc_hash::{FxBuildHasher, FxHashMap, FxHashSet, FxHasher};
use smallvec::SmallVec;

// Import slotmap types for storage backend
#[cfg(not(feature = "dense-slotmap"))]
use slotmap::SlotMap;

#[cfg(feature = "dense-slotmap")]
use slotmap::DenseSlotMap;

// Import SparseSecondaryMap for auxiliary data tracking
use slotmap::SparseSecondaryMap;

// Import key types for use in type aliases
use crate::core::facet::FacetHandle;
use crate::core::triangulation_data_structure::{CellKey, VertexKey};

/// Compact index type for facet positions within a cell.
///
/// Since a D-dimensional cell has D+1 facets, and practical triangulations work with D ≤ 255,
/// a `u8` provides sufficient range while minimizing memory usage.
///
/// # Range
///
/// - **Valid range**: 0..=D for a D-dimensional triangulation
/// - **Maximum supported**: D ≤ 255 (which covers all practical applications)
///
/// # Performance Benefits
///
/// - **Smaller tuples**: `(CellKey, FacetIndex)` uses less memory than `(CellKey, usize)`
/// - **Better cache density**: More facet mappings fit in cache lines
/// - **Reduced memory bandwidth**: Faster iteration over facet collections
///
/// # Examples
///
/// ```rust
/// use delaunay::core::collections::FacetIndex;
///
/// // 3D triangulation: facets 0, 1, 2, 3 (fits comfortably in u8)
/// let facet: FacetIndex = 2;
/// assert_eq!(usize::from(facet), 2);
/// ```
pub type FacetIndex = u8;

// Re-export UUID for convenience in type aliases
pub use uuid::Uuid;

// =============================================================================
// STORAGE BACKEND
// =============================================================================

/// Internal storage backend for triangulation data structures.
///
/// This type alias abstracts over the concrete storage implementation,
/// allowing the choice between `SlotMap` (default) and `DenseSlotMap`
/// (via the `dense-slotmap` feature flag) without exposing the choice
/// in public APIs.
///
/// # Feature Flags
///
/// - **default**: Uses `SlotMap` for balanced performance
/// - **dense-slotmap**: Uses `DenseSlotMap` for denser memory layout
///
/// # Internal Use Only
///
/// This type should not be exposed in public API signatures. Instead,
/// public methods should return iterators or use other abstractions
/// that hide the concrete storage backend.
///
/// # Examples
///
/// ```rust,ignore
/// // Internal use - not exposed in public API
/// let vertices: StorageMap<VertexKey, Vertex<f64, (), 3>> = StorageMap::with_key();
/// ```
#[cfg(not(feature = "dense-slotmap"))]
pub(crate) type StorageMap<K, V> = SlotMap<K, V>;

#[cfg(feature = "dense-slotmap")]
pub(crate) type StorageMap<K, V> = DenseSlotMap<K, V>;

// =============================================================================
// CORE OPTIMIZED TYPES
// =============================================================================

/// Optimized `HashMap` type for performance-critical operations.
/// Uses `FastHasher` (`rustc_hash::FxHasher`) for faster hashing in non-cryptographic contexts.
///
/// # Performance Characteristics
///
/// - **Hash Function**: `FastHasher` (non-cryptographic, very fast)
/// - **Use Case**: Internal mappings where security is not a concern
/// - **Speedup**: ~2-3x faster than `std::collections::HashMap` in typical non-adversarial workloads
///
/// # Security Warning
///
/// ⚠️ **Not DoS-resistant**: Do not use with attacker-controlled keys.
/// Use only with trusted, internal data to avoid hash collision attacks.
///
/// # Examples
///
/// ```rust
/// use delaunay::core::collections::FastHashMap;
///
/// let mut map: FastHashMap<u64, usize> = FastHashMap::default();
/// map.insert(123, 456);
/// ```
pub type FastHashMap<K, V> = FxHashMap<K, V>;
/// Fast non-cryptographic hasher alias for internal collections.
///
/// Wraps [`rustc_hash::FxHasher`] to ensure consistent hashing behavior
/// across [`FastHashMap`] and [`FastHashSet`].
pub type FastHasher = FxHasher;
/// Build hasher that instantiates [`FastHasher`].
///
/// Used by helpers that configure [`FastHashMap`]
/// and [`FastHashSet`] with the optimized hashing strategy.
pub type FastBuildHasher = FxBuildHasher;

/// Re-export the Entry enum for `FastHashMap`.
/// This provides the Entry API for efficient check-and-insert operations.
/// Since `FxHashMap` uses `std::collections::hash_map::Entry`, we re-export that.
///
/// # Examples
///
/// ```rust
/// use delaunay::core::collections::{FastHashMap, Entry};
///
/// let mut map: FastHashMap<String, String> = FastHashMap::default();
/// match map.entry("key".to_string()) {
///     Entry::Occupied(e) => println!("Already exists: {:?}", e.get()),
///     Entry::Vacant(e) => { e.insert("value".to_string()); }
/// }
/// ```
pub use std::collections::hash_map::Entry;

/// Optimized `HashSet` type for performance-critical operations.
/// Uses `FastHasher` (`rustc_hash::FxHasher`) for faster hashing in non-cryptographic contexts.
///
/// # Performance Characteristics
///
/// - **Hash Function**: `FastHasher` (non-cryptographic, very fast)
/// - **Use Case**: Internal sets for membership testing
/// - **Speedup**: ~2-3x faster than `std::collections::HashSet` in typical non-adversarial workloads
///
/// # Security Warning
///
/// ⚠️ **Not DoS-resistant**: Do not use with attacker-controlled keys.
/// Use only with trusted, internal data to avoid hash collision attacks.
///
/// # Examples
///
/// External API usage (UUID-based for compatibility):
/// ```rust
/// use delaunay::core::collections::FastHashSet;
/// use uuid::Uuid;
///
/// let mut set: FastHashSet<Uuid> = FastHashSet::default();
/// set.insert(Uuid::new_v4());
/// ```
///
/// **Phase 1**: Internal operations (key-based for performance):
/// ```rust
/// use delaunay::core::collections::{FastHashSet, CellKeySet};
/// use delaunay::core::triangulation_data_structure::CellKey;
///
/// // For internal algorithms, prefer direct key-based collections
/// let mut internal_set: CellKeySet = CellKeySet::default();
/// // internal_set.insert(cell_key); // Avoids extra UUID→Key lookups
/// ```
pub type FastHashSet<T> = FxHashSet<T>;

/// Small-optimized Vec that uses stack allocation for small collections.
/// Generic size parameter allows customization per use case.
/// Provides heap fallback for larger collections.
///
/// # Performance Characteristics
///
/// - **Stack Allocation**: For collections ≤ N elements
/// - **Heap Fallback**: Automatically grows to heap when needed
/// - **Cache Friendly**: Better memory locality for small collections
/// - **Zero-cost**: No overhead when staying within inline capacity
///
/// # Size Guidelines
///
/// - **N=2**: Facet sharing patterns (1-2 cells per facet)
/// - **N=4**: Small temporary operations
/// - **N=8**: Typical vertex/cell degrees
/// - **N=16**: Batch operation buffers
///
/// # Examples
///
/// ```rust
/// use delaunay::core::collections::SmallBuffer;
///
/// // Stack-allocated for ≤8 elements, heap for more
/// let mut buffer: SmallBuffer<i32, 8> = SmallBuffer::new();
/// for i in 0..5 {
///     buffer.push(i);  // All stack allocated
/// }
/// ```
pub type SmallBuffer<T, const N: usize> = SmallVec<[T; N]>;

// =============================================================================
// TRIANGULATION-SPECIFIC OPTIMIZED TYPES
// =============================================================================

/// Facet-to-cells mapping optimized for typical triangulation patterns.
/// Most facets are shared by at most 2 cells (boundary facets = 1, interior facets = 2).
///
/// # Optimization Rationale
///
/// - **Key**: `u64` facet hash (from vertex combination)
/// - **Value**: `SmallBuffer<FacetHandle, 2>` - stack allocated for typical case
/// - **Typical Pattern**: 1 cell (boundary) or 2 cells (interior facet)
/// - **Performance**: Avoids heap allocation for >95% of facets
/// - **Memory Efficiency**: `FacetHandle` uses u8 for facet index, same size as raw tuple
///
/// # Examples
///
/// ```rust
/// use delaunay::core::collections::FacetToCellsMap;
///
/// let mut facet_map: FacetToCellsMap = FacetToCellsMap::default();
/// // Most entries will use stack allocation
/// ```
pub type FacetToCellsMap = FastHashMap<u64, SmallBuffer<crate::core::facet::FacetHandle, 2>>;

/// Cell neighbor mapping optimized for typical cell degrees.
/// Most cells have a small number of neighbors (D+1 faces, so at most D+1 neighbors).
///
/// # Optimization Rationale
///
/// - **Key**: `CellKey` identifying the cell
/// - **Value**: `NeighborBuffer<Option<CellKey>>` - handles up to 8 neighbors on stack
/// - **Typical Pattern**: 2D=3 neighbors, 3D=4 neighbors, 4D=5 neighbors
/// - **Performance**: Stack allocation for dimensions up to ~7D
///
/// # Note
///
/// This type mirrors `Cell::neighbors()` which returns `Option<&NeighborBuffer<Option<CellKey>>>`.
///
/// # Examples
///
/// ```rust
/// use delaunay::core::collections::CellNeighborsMap;
///
/// let mut neighbors: CellNeighborsMap = CellNeighborsMap::default();
/// // Efficient for typical triangulation dimensions
/// ```
pub type CellNeighborsMap = FastHashMap<CellKey, NeighborBuffer<Option<CellKey>>>;

/// Vertex-to-cells mapping optimized for typical vertex degrees.
/// Most vertices are incident to a small number of cells in well-conditioned triangulations.
///
/// # Optimization Rationale
///
/// - **Key**: `VertexKey` identifying the vertex
/// - **Value**: `SmallBuffer<CellKey, MAX_PRACTICAL_DIMENSION_SIZE>` - handles up to 8 incident cells on stack
/// - **Typical Pattern**: Well-conditioned triangulations have low vertex degrees
/// - **Performance**: Avoids heap allocation for most vertices
///
/// # Examples
///
/// ```rust
/// use delaunay::core::collections::VertexToCellsMap;
///
/// let mut vertex_cells: VertexToCellsMap = VertexToCellsMap::default();
/// // Optimized for typical vertex degrees
/// ```
pub type VertexToCellsMap =
    FastHashMap<VertexKey, SmallBuffer<CellKey, MAX_PRACTICAL_DIMENSION_SIZE>>;

/// Cell vertices mapping optimized for validation operations.
/// Each cell typically has D+1 vertices, stored as a fast set for efficient intersection operations.
///
/// # Optimization Rationale
///
/// - **Key**: `CellKey` identifying the cell
/// - **Value**: `FastHashSet<VertexKey>` - optimized for set operations
/// - **Use Case**: Validation algorithms that need fast intersection/membership testing
/// - **Performance**: `FastHasher` provides fast hashing for `VertexKey`
///
/// # Examples
///
/// ```rust
/// use delaunay::core::collections::CellVerticesMap;
///
/// let mut cell_vertices: CellVerticesMap = CellVerticesMap::default();
/// // Fast set operations for validation
/// ```
pub type CellVerticesMap = FastHashMap<CellKey, FastHashSet<VertexKey>>;

/// Cell vertex keys mapping optimized for validation operations requiring positional access.
/// Each cell typically has D+1 vertices, stored in a stack-allocated buffer for efficiency.
///
/// # Optimization Rationale
///
/// - **Key**: `CellKey` identifying the cell
/// - **Value**: `CellVertexBuffer` - stack-allocated for D ≤ 7, preserves vertex order
/// - **Use Case**: Validation algorithms that need positional vertex access (e.g., neighbors\[i\] opposite vertices\[i\])
/// - **Performance**: Eliminates heap allocation for typical dimensions, better cache locality
///
/// # Examples
///
/// ```rust
/// use delaunay::core::collections::CellVertexKeysMap;
///
/// let mut cell_vertices: CellVertexKeysMap = CellVertexKeysMap::default();
/// // Efficient positional access during validation with stack allocation
/// ```
pub type CellVertexKeysMap = FastHashMap<CellKey, CellVertexBuffer>;

// =============================================================================
// ALGORITHM-SPECIFIC BUFFER TYPES
// =============================================================================

/// Size constant for operations that may affect multiple cells during cleanup.
/// 16 provides generous headroom for duplicate removal and topology repair operations.
///
/// This constant is publicly exposed to allow external modules to derive buffer sizes
/// from it, ensuring consistent sizing across the codebase.
pub const CLEANUP_OPERATION_BUFFER_SIZE: usize = 16;

/// Size constant for operations that work with a small number of valid cells.
/// 4 is sufficient since valid facets are shared by at most 2 cells, with some headroom.
const SMALL_CELL_OPERATION_BUFFER_SIZE: usize = 4;

/// Collection for tracking cells to remove during cleanup operations.
/// Most cleanup operations affect a small number of cells.
///
/// # Optimization Rationale
///
/// - **Stack Allocation**: Up to 16 cells (covers most cleanup scenarios)
/// - **Use Case**: Duplicate cell removal, invalid facet cleanup
/// - **Performance**: Avoids heap allocation for typical cleanup operations
pub type CellRemovalBuffer = SmallBuffer<CellKey, CLEANUP_OPERATION_BUFFER_SIZE>;

/// Collection for tracking Delaunay violations during iterative refinement.
/// Most violation checks find a small number of violating cells.
///
/// # Optimization Rationale
///
/// - **Stack Allocation**: Up to 16 cells (covers most violation scenarios)
/// - **Use Case**: Iterative cavity refinement, Delaunay validation
/// - **Performance**: Avoids heap allocation in hot paths during insertion
/// - **Typical Size**: 0-4 violations in well-conditioned triangulations
pub type ViolationBuffer = SmallBuffer<CellKey, CLEANUP_OPERATION_BUFFER_SIZE>;

/// Collection for tracking cell keys during insertion operations.
/// Most insertion operations create a small number of cells.
///
/// # Optimization Rationale
///
/// - **Stack Allocation**: Up to 16 cells (covers most insertion scenarios)
/// - **Use Case**: Cavity-based insertion, cell creation tracking
/// - **Performance**: Avoids heap allocation during cell creation
/// - **Typical Size**: 4-8 cells in well-conditioned triangulations (D+1 for simple cavity)
pub type CellKeyBuffer = SmallBuffer<CellKey, CLEANUP_OPERATION_BUFFER_SIZE>;

/// Collection for tracking bad cells (Delaunay violations) during insertion.
/// Bad cells are those whose circumsphere contains the newly inserted point.
///
/// # Optimization Rationale
///
/// - **Stack Allocation**: Up to 16 cells (covers most cavity scenarios)
/// - **Use Case**: Bowyer-Watson algorithm, `find_bad_cells()` return type
/// - **Performance**: Avoids heap allocation in hot path during point insertion
/// - **Typical Size**: 1-8 cells in well-conditioned triangulations
///
/// # Usage
///
/// This buffer is used as the return type for `find_bad_cells()` and related methods.
/// The capacity of 16 is generous for typical Delaunay cavities while remaining stack-allocated.
///
/// # Examples
///
/// ```rust
/// use delaunay::core::collections::BadCellBuffer;
/// use delaunay::core::triangulation_data_structure::CellKey;
///
/// // Accumulate bad cells during Bowyer-Watson insertion
/// let mut bad_cells: BadCellBuffer = BadCellBuffer::new();
/// // bad_cells.push(cell_key); // Stack allocated for typical cavities
/// ```
pub type BadCellBuffer = SmallBuffer<CellKey, CLEANUP_OPERATION_BUFFER_SIZE>;

/// Collection for tracking valid cells during facet sharing fixes.
/// Most invalid sharing situations involve only a few cells per facet.
///
/// # Optimization Rationale
///
/// - **Stack Allocation**: Up to 4 cells (more than enough for valid facets)
/// - **Use Case**: Facet validation, topology repair
/// - **Performance**: Stack-only for typical geometric repair operations
pub type ValidCellsBuffer = SmallBuffer<CellKey, SMALL_CELL_OPERATION_BUFFER_SIZE>;

/// Buffer for storing facet information during boundary analysis.
/// Sized for typical cell operations (D+1 facets per cell).
///
/// # Optimization Rationale
///
/// - **Stack Allocation**: Up to `MAX_PRACTICAL_DIMENSION_SIZE` facet handles
/// - **Use Case**: Boundary analysis, facet enumeration
/// - **Performance**: Handles cells up to 7D on stack
/// - **Type Safety**: Uses `FacetHandle` instead of raw tuples to prevent errors
///
/// # Type Safety
///
/// This buffer uses `FacetHandle` rather than `(CellKey, FacetIndex)` tuples to:
/// - Prevent accidental swapping of `cell_key` and `facet_index`
/// - Make the API more self-documenting
/// - Enable future extensions without breaking changes
pub type FacetInfoBuffer = SmallBuffer<FacetHandle, MAX_PRACTICAL_DIMENSION_SIZE>;

/// Buffer for storing cells that share a facet.
/// Facets are shared by at most 2 cells (boundary=1, interior=2).
///
/// # Optimization Rationale
///
/// - **Stack Allocation**: Exactly 2 cells (no heap allocation for valid triangulations)
/// - **Use Case**: Facet-to-cells mapping validation, cavity boundary detection
/// - **Performance**: Eliminates heap allocation when invariant holds (≤2 cells per facet)
/// - **Memory Efficiency**: 2 × 8 bytes = 16 bytes on stack per facet
///
/// # Invariant
///
/// Valid triangulations have the following facet sharing invariants:
/// - **Boundary facets**: Shared by exactly 1 cell (hull facets)
/// - **Interior facets**: Shared by exactly 2 cells (adjacent cells)
/// - **Invalid**: Shared by >2 cells (indicates TDS corruption)
///
/// # Examples
///
/// ```rust
/// use delaunay::core::collections::FacetSharingCellsBuffer;
/// use delaunay::core::triangulation_data_structure::CellKey;
///
/// // Store cells sharing a facet (always ≤2 cells)
/// let mut sharing_cells: FacetSharingCellsBuffer = FacetSharingCellsBuffer::new();
/// // sharing_cells.push(cell_key); // Stack allocated, no heap
/// ```
pub type FacetSharingCellsBuffer = SmallBuffer<CellKey, 2>;

// =============================================================================
// SEMANTIC SIZE CONSTANTS AND TYPE ALIASES
// =============================================================================

/// Semantic constant for the maximum practical dimension in computational geometry.
///
/// Most applications work with dimensions 2D-5D, so 8 provides comfortable headroom
/// while keeping stack allocation efficient.
pub const MAX_PRACTICAL_DIMENSION_SIZE: usize = 8;

/// Buffer sized for vertex collections in D-dimensional simplices.
/// A D-dimensional simplex has D+1 vertices, so this handles up to 7D simplices on stack.
///
/// # Use Cases
/// - Cell vertex operations
/// - Simplex construction
/// - Geometric predicate vertex lists
pub type SimplexVertexBuffer<T> = SmallBuffer<T, MAX_PRACTICAL_DIMENSION_SIZE>;

/// Buffer sized for UUID collections in vertex operations.
/// Optimized for storing vertex UUIDs from a single simplex (D+1 UUIDs).
///
/// # Use Cases
/// - Duplicate cell detection
/// - Vertex uniqueness checks
/// - Cell vertex UUID collections
pub type VertexUuidBuffer = SimplexVertexBuffer<Uuid>;

/// Buffer sized for `VertexKey` collections in validation and internal operations.
/// Handles vertex keys from a single D-dimensional simplex.
///
/// # Use Cases
/// - Validation algorithms
/// - Internal vertex key tracking
/// - Cell vertex key collections
pub type VertexKeyBuffer = SimplexVertexBuffer<VertexKey>;

/// Buffer for storing cell neighbors (D+1 neighbors for a D-dimensional cell).
/// Uses stack allocation for typical dimensions (2D-7D).
///
/// # Optimization Rationale
///
/// - **Stack Allocation**: D+1 neighbors fit on stack for D ≤ 7
/// - **Use Case**: Neighbor queries, neighbor assignment, validation
/// - **Performance**: Avoids heap allocation in 90%+ of cases
/// - **Memory Layout**: Better cache locality than heap-allocated Vec
///
/// # Examples
///
/// ```rust
/// use delaunay::core::collections::NeighborBuffer;
/// use delaunay::core::triangulation_data_structure::CellKey;
///
/// // Store neighbor keys for a 3D cell (4 neighbors)
/// let mut neighbors: NeighborBuffer<Option<CellKey>> = NeighborBuffer::new();
/// // neighbors.push(Some(cell_key)); // Stack allocated
/// ```
pub type NeighborBuffer<T> = SmallBuffer<T, MAX_PRACTICAL_DIMENSION_SIZE>;

/// Buffer for vertex key collections from a single cell (D+1 vertices).
/// Avoids heap allocation for typical triangulation dimensions.
///
/// # Optimization Rationale
///
/// - **Stack Allocation**: D+1 vertex keys fit on stack for D ≤ 7
/// - **Use Case**: Cell vertex storage, validation, geometric operations
/// - **Performance**: Eliminates heap allocation for typical dimensions
/// - **Ordering**: Preserves vertex order for positional semantics
///
/// # Examples
///
/// ```rust
/// use delaunay::core::collections::CellVertexBuffer;
/// use delaunay::core::triangulation_data_structure::VertexKey;
///
/// // Store vertex keys for a 3D cell (4 vertices)
/// let mut vertices: CellVertexBuffer = CellVertexBuffer::new();
/// // vertices.push(vertex_key); // Stack allocated
/// ```
pub type CellVertexBuffer = SmallBuffer<VertexKey, MAX_PRACTICAL_DIMENSION_SIZE>;

/// Buffer for vertex UUID collections from a single cell (D+1 vertex UUIDs).
/// Uses stack allocation to avoid heap overhead for cell operations.
///
/// # Optimization Rationale
///
/// - **Stack Allocation**: D+1 vertex UUIDs fit on stack for D ≤ 7
/// - **Use Case**: Extracting vertex UUIDs from a cell, validation, duplicate detection
/// - **Performance**: Avoids allocation for temporary UUID collections
/// - **Memory Efficiency**: 16 bytes per UUID × 8 = 128 bytes on stack
///
/// # Examples
///
/// ```rust
/// use delaunay::core::collections::CellVertexUuidBuffer;
/// use uuid::Uuid;
///
/// // Store vertex UUIDs from a cell
/// let mut vertex_uuids: CellVertexUuidBuffer = CellVertexUuidBuffer::new();
/// // vertex_uuids.push(vertex.uuid()); // Stack allocated
/// ```
pub type CellVertexUuidBuffer = SmallBuffer<Uuid, MAX_PRACTICAL_DIMENSION_SIZE>;

/// Buffer sized for Point collections in geometric operations.
/// Generic over coordinate type T and dimension D, with practical size limit.
///
/// # Use Cases
/// - Geometric predicate operations
/// - Simplex coordinate collections
/// - Temporary point storage during algorithms
pub type GeometricPointBuffer<T, const D: usize> =
    SmallBuffer<[T; D], MAX_PRACTICAL_DIMENSION_SIZE>;

// =============================================================================
// GEOMETRIC ALGORITHM TYPES
// =============================================================================

/// Optimized set for vertex UUID collections in geometric predicates.
/// Used for fast membership testing during facet analysis.
///
/// # Optimization Rationale
///
/// - **Hash Function**: `FastHasher` for fast UUID hashing
/// - **Use Case**: Membership testing, intersection operations
/// - **Performance**: ~2-3x faster than `std::collections::HashSet`
pub type VertexUuidSet = FastHashSet<Uuid>;

/// Mapping from facet keys to vertex sets for hull algorithms.
/// Used in convex hull and Voronoi diagram construction.
///
/// # Optimization Rationale
///
/// - **Key**: `u64` facet hash for O(1) lookup
/// - **Value**: `VertexUuidSet` for fast set operations
/// - **Use Case**: Hull algorithms, visibility determination
/// - **Performance**: Optimized for geometric algorithm patterns
pub type FacetVertexMap = FastHashMap<u64, VertexUuidSet>;

/// Mapping from cell UUIDs to their vertex UUIDs (optimized for internal operations).
/// Uses stack-allocated buffers for vertex UUID storage.
///
/// # Optimization Rationale
///
/// - **Key**: Cell UUID for stable identification
/// - **Value**: `CellVertexUuidBuffer` for stack-allocated vertex UUID storage (D+1 UUIDs)
/// - **Use Case**: Internal operations, temporary mappings, validation
/// - **Performance**: Stack allocation for typical cell vertex counts, avoids heap for D ≤ 7
///
/// # Serialization Note
///
/// For serialization/deserialization, use `FastHashMap<Uuid, Vec<Uuid>>` instead,
/// as serde doesn't natively serialize `SmallVec`. Convert using `.to_vec()` when serializing.
///
/// # Examples
///
/// ```rust
/// use delaunay::core::collections::CellToVertexUuidsMap;
/// use uuid::Uuid;
///
/// // Internal usage with stack allocation
/// let mut mapping: CellToVertexUuidsMap = CellToVertexUuidsMap::default();
/// // mapping.insert(cell_uuid, vertex_uuids_buffer);
/// ```
pub type CellToVertexUuidsMap = FastHashMap<Uuid, CellVertexUuidBuffer>;

// =============================================================================
// UUID-KEY MAPPING TYPES
// =============================================================================

/// Optimized mapping from Vertex UUIDs to `VertexKeys` for fast UUID → Key lookups.
/// This is the primary direction for most triangulation operations.
///
/// # Optimization Rationale
///
/// - **Primary Direction**: UUID → Key is the hot path in most algorithms
/// - **Hash Function**: `FastHasher` provides ~2-3x faster lookups than default hasher in typical non-adversarial workloads
/// - **Use Case**: Converting vertex UUIDs to keys for `SlotMap` access
/// - **Performance**: O(1) average case, optimized for triangulation algorithms
///
/// # Reverse Lookups
///
/// For Key → UUID lookups (less common), use direct `SlotMap` access:
/// ```rust
/// use delaunay::core::triangulation_data_structure::Tds;
/// use delaunay::vertex;
///
/// let vertices = vec![
///     vertex!([0.0, 0.0, 0.0]),
///     vertex!([1.0, 0.0, 0.0]),
///     vertex!([0.0, 1.0, 0.0]),
///     vertex!([0.0, 0.0, 1.0]),
/// ];
/// let tds: Tds<f64, (), (), 3> = Tds::new(&vertices).unwrap();
///
/// // Get first vertex key and its UUID
/// let (vertex_key, _) = tds.vertices().next().unwrap();
/// let vertex_uuid = tds.get_vertex_by_key(vertex_key).unwrap().uuid();
/// ```
pub type UuidToVertexKeyMap = FastHashMap<Uuid, VertexKey>;

/// Optimized mapping from Cell UUIDs to `CellKeys` for fast UUID → Key lookups.
/// This is the primary direction for most triangulation operations.
///
/// # Optimization Rationale
///
/// - **Primary Direction**: UUID → Key is the hot path in neighbor assignment
/// - **Hash Function**: `FastHasher` provides ~2-3x faster lookups than default hasher in typical non-adversarial workloads
/// - **Use Case**: Converting cell UUIDs to keys for `SlotMap` access
/// - **Performance**: O(1) average case, optimized for triangulation algorithms
///
/// # Reverse Lookups
///
/// For Key → UUID lookups (less common), use direct `SlotMap` access:
/// ```rust
/// use delaunay::core::triangulation_data_structure::Tds;
/// use delaunay::vertex;
///
/// let vertices = vec![
///     vertex!([0.0, 0.0, 0.0]),
///     vertex!([1.0, 0.0, 0.0]),
///     vertex!([0.0, 1.0, 0.0]),
///     vertex!([0.0, 0.0, 1.0]),
/// ];
/// let tds: Tds<f64, (), (), 3> = Tds::new(&vertices).unwrap();
///
/// // Get first cell key and its UUID
/// let (cell_key, _) = tds.cells().next().unwrap();
/// let cell_uuid = tds.get_cell(cell_key).unwrap().uuid();
/// ```
pub type UuidToCellKeyMap = FastHashMap<Uuid, CellKey>;

// =============================================================================
// PHASE 1 MIGRATION: KEY-BASED INTERNAL TYPES
// =============================================================================

/// **Phase 1 Migration**: Optimized set for `CellKey` collections in internal operations.
///
/// This eliminates UUID dependencies in internal algorithms by working directly with `SlotMap` keys.
/// Provides the same performance benefits as `FastHashSet` but for direct key operations.
///
/// # Performance Benefits
///
/// - **Avoids UUID→Key lookups**: Eliminates extra hash table lookups vs UUID→Key mapping
/// - **Direct `SlotMap` compatibility**: Keys can be used directly for data structure access
/// - **Memory efficiency**: `CellKey` is typically smaller than `Uuid` (8 bytes vs 16 bytes)
/// - **Cache friendly**: Better memory locality for key-based algorithms
///
/// # Use Cases
///
/// - Internal cell tracking during algorithms
/// - Validation operations that work with cell keys
/// - Temporary cell collections in geometric operations
///
/// # Examples
///
/// ```rust
/// use delaunay::core::collections::CellKeySet;
/// use delaunay::core::triangulation_data_structure::CellKey;
///
/// // Direct key-based operations (Phase 1 internal algorithms)
/// let mut cell_set: CellKeySet = CellKeySet::default();
/// // cell_key comes from SlotMap operations, no UUID lookups needed
/// // cell_set.insert(cell_key);
/// ```
pub type CellKeySet = FastHashSet<CellKey>;

/// **Phase 1 Migration**: Optimized set for `VertexKey` collections in internal operations.
///
/// This eliminates UUID dependencies in internal algorithms by working directly with `SlotMap` keys.
/// Provides the same performance benefits as `FastHashSet` but for direct key operations.
///
/// # Performance Benefits
///
/// - **Avoids UUID→Key lookups**: Eliminates extra hash table lookups vs UUID→Key mapping
/// - **Direct `SlotMap` compatibility**: Keys can be used directly for data structure access
/// - **Memory efficiency**: `VertexKey` is typically smaller than `Uuid` (8 bytes vs 16 bytes)
/// - **Cache friendly**: Better memory locality for key-based algorithms
///
/// # Use Cases
///
/// - Internal vertex tracking during algorithms
/// - Validation operations that work with vertex keys
/// - Temporary vertex collections in geometric operations
///
/// # Examples
///
/// ```rust
/// use delaunay::core::collections::VertexKeySet;
/// use delaunay::core::triangulation_data_structure::VertexKey;
///
/// // Direct key-based operations (Phase 1 internal algorithms)
/// let mut vertex_set: VertexKeySet = VertexKeySet::default();
/// // vertex_key comes from SlotMap operations, no UUID lookups needed
/// // vertex_set.insert(vertex_key);
/// ```
pub type VertexKeySet = FastHashSet<VertexKey>;

/// **Phase 1 Migration**: Key-based mapping for internal cell operations.
///
/// This provides direct `CellKey` → Value mapping without requiring UUID lookups,
/// optimizing internal algorithms that work with cell keys.
///
/// # Performance Benefits
///
/// - **Direct key access**: No intermediate UUID→Key mapping required
/// - **`SlotMap` integration**: Keys align perfectly with internal data structure access patterns
/// - **Memory efficiency**: Avoids storing redundant UUID→Key associations
/// - **Algorithm optimization**: Direct key operations eliminate extra lookups in hot paths
///
/// # Use Cases
///
/// - Internal cell metadata storage
/// - Algorithm state tracking per cell
/// - Temporary mappings during geometric operations
/// - Validation data associated with specific cells
///
/// # Examples
///
/// ```rust
/// use delaunay::core::collections::KeyBasedCellMap;
/// use delaunay::core::triangulation_data_structure::CellKey;
///
/// // Direct key-based mapping (Phase 1 internal algorithms)
/// let mut cell_data: KeyBasedCellMap<f64> = KeyBasedCellMap::default();
/// // cell_key comes from SlotMap, value is algorithm-specific data
/// // cell_data.insert(cell_key, 42.0);
/// ```
pub type KeyBasedCellMap<V> = FastHashMap<CellKey, V>;

/// **Phase 1 Migration**: Key-based mapping for internal vertex operations.
///
/// This provides direct `VertexKey` → Value mapping without requiring UUID lookups,
/// optimizing internal algorithms that work with vertex keys.
///
/// # Performance Benefits
///
/// - **Direct key access**: No intermediate UUID→Key mapping required
/// - **`SlotMap` integration**: Keys align perfectly with internal data structure access patterns
/// - **Memory efficiency**: Avoids storing redundant UUID→Key associations
/// - **Algorithm optimization**: Direct key operations eliminate extra lookups in hot paths
///
/// # Use Cases
///
/// - Internal vertex metadata storage
/// - Algorithm state tracking per vertex
/// - Temporary mappings during geometric operations
/// - Validation data associated with specific vertices
///
/// # Examples
///
/// ```rust
/// use delaunay::core::collections::KeyBasedVertexMap;
/// use delaunay::core::triangulation_data_structure::VertexKey;
///
/// // Direct key-based mapping (Phase 1 internal algorithms)
/// let mut vertex_data: KeyBasedVertexMap<String> = KeyBasedVertexMap::default();
/// // vertex_key comes from SlotMap, value is algorithm-specific data
/// // vertex_data.insert(vertex_key, "metadata".to_string());
/// ```
pub type KeyBasedVertexMap<V> = FastHashMap<VertexKey, V>;

// NOTE: KeyBasedNeighborMap was removed as it was:
// 1. Not used anywhere in the codebase
// 2. Incorrectly defined as a 1:1 mapping when cells have D+1 neighbors
// 3. Redundant - Cell.neighbors already uses CellKey directly (no migration needed)
//
// Neighbor storage is already key-based:
// - Cell.neighbors: Option<SmallBuffer<Option<CellKey>, MAX_PRACTICAL_DIMENSION_SIZE>>
// - CellNeighborsMap: FastHashMap<CellKey, SmallBuffer<Option<CellKey>, MAX_PRACTICAL_DIMENSION_SIZE>>
// Both types use CellKey for neighbor references, providing direct SlotMap access without UUID lookups.

// =============================================================================
// SLOTMAP SECONDARY MAPS FOR AUXILIARY DATA
// =============================================================================

/// Sparse secondary map for tracking auxiliary data associated with cells.
///
/// This is the idiomatic way to associate temporary data with `SlotMap` keys during algorithms.
/// Only stores entries for cells that have associated data (sparse representation).
///
/// # Performance Benefits
///
/// - **Memory efficient**: Only allocates for cells with data (vs dense array)
/// - **Type safe**: Can only use valid `CellKey` from the primary `SlotMap`
/// - **Cache friendly**: Better locality than separate `HashMap<CellKey, V>`
/// - **`SlotMap` integration**: Designed specifically for this use case
///
/// # Use Cases
///
/// - **Phase 3 algorithms**: Conflict region finding, cavity extraction
/// - **Algorithm state**: Marking cells as "visited", "in conflict", "processed"
/// - **Temporary data**: Associating algorithm-specific data with cells
///
/// # Examples
///
/// ```rust
/// use delaunay::core::collections::CellSecondaryMap;
/// use delaunay::core::triangulation_data_structure::{Tds, CellKey};
/// use delaunay::vertex;
///
/// let vertices = vec![
///     vertex!([0.0, 0.0, 0.0]),
///     vertex!([1.0, 0.0, 0.0]),
///     vertex!([0.0, 1.0, 0.0]),
///     vertex!([0.0, 0.0, 1.0]),
/// ];
/// let tds: Tds<f64, (), (), 3> = Tds::new(&vertices).unwrap();
///
/// // Track which cells are in conflict with a new point
/// let mut in_conflict: CellSecondaryMap<bool> = CellSecondaryMap::new();
/// for (cell_key, _) in tds.cells() {
///     in_conflict.insert(cell_key, true);
/// }
/// ```
pub type CellSecondaryMap<V> = SparseSecondaryMap<CellKey, V>;

/// Sparse secondary map for tracking auxiliary data associated with vertices.
///
/// This is the idiomatic way to associate temporary data with `SlotMap` keys during algorithms.
/// Only stores entries for vertices that have associated data (sparse representation).
///
/// # Performance Benefits
///
/// - **Memory efficient**: Only allocates for vertices with data (vs dense array)
/// - **Type safe**: Can only use valid `VertexKey` from the primary `SlotMap`
/// - **Cache friendly**: Better locality than separate `HashMap<VertexKey, V>`
/// - **`SlotMap` integration**: Designed specifically for this use case
///
/// # Use Cases
///
/// - **Algorithm state**: Marking vertices as "visited", "processed", "boundary"
/// - **Distance tracking**: Shortest path, geodesic distance computations
/// - **Temporary data**: Associating algorithm-specific data with vertices
///
/// # Examples
///
/// ```rust
/// use delaunay::core::collections::VertexSecondaryMap;
/// use delaunay::core::triangulation_data_structure::{Tds, VertexKey};
/// use delaunay::vertex;
///
/// let vertices = vec![
///     vertex!([0.0, 0.0, 0.0]),
///     vertex!([1.0, 0.0, 0.0]),
///     vertex!([0.0, 1.0, 0.0]),
///     vertex!([0.0, 0.0, 1.0]),
/// ];
/// let tds: Tds<f64, (), (), 3> = Tds::new(&vertices).unwrap();
///
/// // Track vertex processing order
/// let mut processing_order: VertexSecondaryMap<usize> = VertexSecondaryMap::new();
/// for (idx, (vertex_key, _)) in tds.vertices().enumerate() {
///     processing_order.insert(vertex_key, idx);
/// }
/// ```
pub type VertexSecondaryMap<V> = SparseSecondaryMap<VertexKey, V>;

/// Size constant for batch point processing operations.
/// 16 provides sufficient capacity for typical geometric algorithm batches.
const BATCH_PROCESSING_BUFFER_SIZE: usize = 16;

/// Temporary buffer for storing points during geometric operations.
/// Sized for typical batch processing operations.
///
/// # Optimization Rationale
///
/// - **Stack Allocation**: Up to 16 points for batch operations
/// - **Generic Dimension**: Works with any coordinate type and dimension
/// - **Use Case**: Point processing, geometric transformations
/// - **Performance**: Avoids allocation for small point batches
pub type PointBuffer<T, const D: usize> = SmallBuffer<[T; D], BATCH_PROCESSING_BUFFER_SIZE>;

// =============================================================================
// UTILITY FUNCTIONS
// =============================================================================

/// Creates a `FastHashMap` with pre-allocated capacity using the optimal hasher.
/// This is more efficient than using the default constructor when the expected size is known.
///
/// # Performance Benefits
///
/// - **Pre-allocation**: Avoids rehashing during insertion
/// - **Optimal Hasher**: Uses `FastHasher` for maximum performance
/// - **Memory Efficiency**: Reduces memory fragmentation
///
/// # Examples
///
/// ```rust
/// use delaunay::core::collections::fast_hash_map_with_capacity;
///
/// let map = fast_hash_map_with_capacity::<u64, usize>(1000);
/// // Can insert up to ~750 items without rehashing (load factor ~0.75)
/// ```
#[inline]
#[must_use]
pub fn fast_hash_map_with_capacity<K, V>(capacity: usize) -> FastHashMap<K, V> {
    FastHashMap::with_capacity_and_hasher(capacity, FastBuildHasher::default())
}

/// Creates a `FastHashSet` with pre-allocated capacity using the optimal hasher.
/// This is more efficient than using the default constructor when the expected size is known.
///
/// # Performance Benefits
///
/// - **Pre-allocation**: Avoids rehashing during insertion
/// - **Optimal Hasher**: Uses `FastHasher` for maximum performance
/// - **Memory Efficiency**: Reduces memory fragmentation
///
/// # Examples
///
/// External API usage (UUID-based):
/// ```rust
/// use delaunay::core::collections::fast_hash_set_with_capacity;
/// use uuid::Uuid;
///
/// let set = fast_hash_set_with_capacity::<Uuid>(500);
/// // Can insert up to ~375 UUIDs without rehashing
/// ```
///
/// **Phase 1**: Internal operations (key-based for better performance):
/// ```rust
/// use delaunay::core::collections::fast_hash_set_with_capacity;
/// use delaunay::core::triangulation_data_structure::CellKey;
///
/// let set = fast_hash_set_with_capacity::<CellKey>(500);
/// // Can insert up to ~375 CellKeys without rehashing, avoids UUID→Key lookups
/// ```
#[inline]
#[must_use]
pub fn fast_hash_set_with_capacity<T>(capacity: usize) -> FastHashSet<T> {
    FastHashSet::with_capacity_and_hasher(capacity, FastBuildHasher::default())
}

/// Creates a `SmallBuffer` with the specified capacity.
/// Uses stack allocation if the capacity is within the inline size, otherwise uses heap.
///
/// Note: This function is only available for specific sizes due to `SmallVec`'s Array trait constraints.
/// For most use cases, prefer using `SmallBuffer::with_capacity(capacity)` directly with concrete types.
///
/// # Performance Benefits
///
/// - **Smart Allocation**: Uses stack when possible, heap when necessary
/// - **Capacity Hinting**: Pre-allocates heap space if needed
/// - **Zero Overhead**: No cost when staying within inline capacity
///
/// # Examples
///
/// ```rust
/// use delaunay::core::collections::SmallBuffer;
///
/// // Use concrete types directly (preferred)
/// let mut small_buf: SmallBuffer<i32, 8> = SmallBuffer::with_capacity(5);
/// let mut large_buf: SmallBuffer<i32, 8> = SmallBuffer::with_capacity(20);
/// ```
#[must_use]
pub fn small_buffer_with_capacity_8<T>(capacity: usize) -> SmallBuffer<T, 8> {
    SmallBuffer::with_capacity(capacity)
}

/// Creates a small buffer optimized for 2 elements (common facet sharing pattern)
#[must_use]
pub fn small_buffer_with_capacity_2<T>(capacity: usize) -> SmallBuffer<T, 2> {
    SmallBuffer::with_capacity(capacity)
}

/// Creates a small buffer optimized for 16 elements (larger batch operations)
#[must_use]
pub fn small_buffer_with_capacity_16<T>(capacity: usize) -> SmallBuffer<T, 16> {
    SmallBuffer::with_capacity(capacity)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_fast_collections_basic_operations() {
        // Test FastHashMap basic operations
        let mut map: FastHashMap<u64, usize> = FastHashMap::default();
        assert!(map.is_empty());

        map.insert(123, 456);
        assert_eq!(map.get(&123), Some(&456));
        assert_eq!(map.len(), 1);

        map.insert(789, 101_112);
        assert_eq!(map.len(), 2);

        // Test FastHashSet basic operations
        let mut set: FastHashSet<u64> = FastHashSet::default();
        assert!(set.is_empty());

        set.insert(789);
        assert!(set.contains(&789));
        assert_eq!(set.len(), 1);

        set.insert(456);
        assert_eq!(set.len(), 2);
        assert!(set.contains(&456));
        assert!(!set.contains(&999));
    }

    #[test]
    fn test_small_buffer_stack_allocation() {
        let mut buffer: SmallBuffer<i32, 4> = SmallBuffer::new();

        // These should use stack allocation
        for i in 0..4 {
            buffer.push(i);
        }
        assert_eq!(buffer.len(), 4);
        assert!(!buffer.spilled()); // Still on stack

        // This should trigger heap allocation
        buffer.push(4);
        assert_eq!(buffer.len(), 5);
        assert!(buffer.spilled()); // Now on heap
    }

    #[test]
    fn test_capacity_helpers() {
        // Test hash map and set capacity helpers
        let map = fast_hash_map_with_capacity::<u64, usize>(100);
        assert!(map.capacity() >= 100);

        let set = fast_hash_set_with_capacity::<u64>(50);
        assert!(set.capacity() >= 50);

        // Test small buffer capacity helpers with spill validation
        let mut buffer_8 = small_buffer_with_capacity_8::<i32>(5);
        assert!(buffer_8.capacity() >= 5);
        // Force growth beyond inline 8 to validate spill
        for i in 0..9 {
            buffer_8.push(i);
        }
        assert!(buffer_8.spilled());

        // Test small_buffer_with_capacity_2 with spill validation
        let mut buffer_2 = small_buffer_with_capacity_2::<i32>(10);
        assert!(buffer_2.capacity() >= 10);
        buffer_2.extend(0..3); // > inline(2) -> heap
        assert!(buffer_2.spilled());

        // Test small_buffer_with_capacity_16 with spill validation
        let mut buffer_16 = small_buffer_with_capacity_16::<String>(25);
        assert!(buffer_16.capacity() >= 25);
        buffer_16.extend(std::iter::repeat_n(String::new(), 17)); // > inline(16)
        assert!(buffer_16.spilled());

        // Test different types work correctly
        let mut test_buffer2: SmallBuffer<f64, 2> = small_buffer_with_capacity_2(3);
        test_buffer2.push(1.0);
        test_buffer2.push(2.0);
        assert_eq!(test_buffer2.len(), 2);

        let mut test_buffer16: SmallBuffer<char, 16> = small_buffer_with_capacity_16(5);
        test_buffer16.push('a');
        test_buffer16.push('b');
        assert_eq!(test_buffer16.len(), 2);

        // Test zero capacity edge case
        let _buffer2_zero = small_buffer_with_capacity_2::<u8>(0);
        let _buffer16_zero = small_buffer_with_capacity_16::<u32>(0);
    }

    #[test]
    fn test_collection_type_instantiation() {
        use crate::core::triangulation_data_structure::{CellKey, VertexKey};
        use slotmap::SlotMap;

        // Test domain-specific UUID-based types compile and instantiate
        let _facet_map: FacetToCellsMap = FacetToCellsMap::default();
        let _neighbors: CellNeighborsMap = CellNeighborsMap::default();
        let _vertex_cells: VertexToCellsMap = VertexToCellsMap::default();
        let _cell_vertices: CellVerticesMap = CellVerticesMap::default();

        // Test CellVertexKeysMap with SmallBuffer for D+1 usage pattern
        let mut cell_vertex_keys: CellVertexKeysMap = CellVertexKeysMap::default();
        let mut cell_slots: SlotMap<CellKey, i32> = SlotMap::default();
        let mut vertex_slots: SlotMap<VertexKey, i32> = SlotMap::default();

        let cell_key = cell_slots.insert(1);
        let mut vertex_buffer: CellVertexBuffer = CellVertexBuffer::new();
        // Simulate D+1 vertices for a 2D cell (3 vertices)
        for _ in 0..3 {
            vertex_buffer.push(vertex_slots.insert(1));
        }
        assert!(!vertex_buffer.spilled()); // Should be on stack for D=2
        cell_vertex_keys.insert(cell_key, vertex_buffer);
        assert_eq!(cell_vertex_keys.len(), 1);

        // Test Phase 1 key-based types compile and instantiate
        let _cell_set: CellKeySet = CellKeySet::default();
        let _vertex_set: VertexKeySet = VertexKeySet::default();
        let _cell_map: KeyBasedCellMap<i32> = KeyBasedCellMap::default();
        let _vertex_map: KeyBasedVertexMap<String> = KeyBasedVertexMap::default();

        // Test basic operations work on key-based types
        let cell_set: CellKeySet = CellKeySet::default();
        assert!(cell_set.is_empty());
        assert_eq!(cell_set.len(), 0);

        let cell_map: KeyBasedCellMap<f64> = KeyBasedCellMap::default();
        assert!(cell_map.is_empty());
        assert_eq!(cell_map.len(), 0);
    }

    #[test]
    fn test_cell_vertex_buffer_stack_allocation_boundary() {
        use crate::core::triangulation_data_structure::VertexKey;
        use slotmap::SlotMap;

        let mut vertex_slots: SlotMap<VertexKey, i32> = SlotMap::default();

        // Test D=7 case: 8 vertices (D+1) should stay on stack
        // MAX_PRACTICAL_DIMENSION_SIZE is 8, so inline capacity is 8
        let mut buffer_d7: CellVertexBuffer = CellVertexBuffer::new();
        for _ in 0..8 {
            buffer_d7.push(vertex_slots.insert(1));
        }
        assert_eq!(buffer_d7.len(), 8);
        assert!(
            !buffer_d7.spilled(),
            "D=7 (8 vertices) should stay on stack"
        );

        // Test D=8 case: 9 vertices (D+1) should spill to heap
        let mut buffer_d8: CellVertexBuffer = CellVertexBuffer::new();
        for _ in 0..9 {
            buffer_d8.push(vertex_slots.insert(1));
        }
        assert_eq!(buffer_d8.len(), 9);
        assert!(buffer_d8.spilled(), "D=8 (9 vertices) should spill to heap");

        // Validate the constant MAX_PRACTICAL_DIMENSION_SIZE=8 is correctly sized
        // for practical use cases (D=0 through D=7)
    }

    #[test]
    fn test_phase1_key_based_roundtrip_operations() {
        use crate::core::triangulation_data_structure::{CellKey, VertexKey};
        use slotmap::SlotMap;

        // Create mock SlotMaps to generate real keys for testing
        let mut cell_slots: SlotMap<CellKey, i32> = SlotMap::default();
        let mut vertex_slots: SlotMap<VertexKey, i32> = SlotMap::default();

        // Insert some dummy data to get real keys
        let cell_key1 = cell_slots.insert(1);
        let cell_key2 = cell_slots.insert(2);
        let vertex_key1 = vertex_slots.insert(1);
        let vertex_key2 = vertex_slots.insert(2);

        // Test CellKeySet insert/contains roundtrip
        let mut cell_set: CellKeySet = CellKeySet::default();
        assert!(!cell_set.contains(&cell_key1));
        cell_set.insert(cell_key1);
        assert!(cell_set.contains(&cell_key1));
        assert!(!cell_set.contains(&cell_key2));

        // Test VertexKeySet insert/contains roundtrip
        let mut vertex_set: VertexKeySet = VertexKeySet::default();
        assert!(!vertex_set.contains(&vertex_key1));
        vertex_set.insert(vertex_key1);
        assert!(vertex_set.contains(&vertex_key1));
        assert!(!vertex_set.contains(&vertex_key2));

        // Test KeyBasedCellMap insert/get roundtrip
        let mut cell_map: KeyBasedCellMap<String> = KeyBasedCellMap::default();
        assert_eq!(cell_map.get(&cell_key1), None);
        cell_map.insert(cell_key1, "cell_data".to_string());
        assert_eq!(
            cell_map.get(&cell_key1).map(String::as_str),
            Some("cell_data")
        );
        assert_eq!(cell_map.get(&cell_key2), None);

        // Test KeyBasedVertexMap insert/get roundtrip
        let mut vertex_map: KeyBasedVertexMap<i32> = KeyBasedVertexMap::default();
        assert_eq!(vertex_map.get(&vertex_key1), None);
        vertex_map.insert(vertex_key1, 42);
        assert_eq!(vertex_map.get(&vertex_key1).copied(), Some(42));
        assert_eq!(vertex_map.get(&vertex_key2), None);

        // Test that collections have expected sizes
        assert_eq!(cell_set.len(), 1);
        assert_eq!(vertex_set.len(), 1);
        assert_eq!(cell_map.len(), 1);
        assert_eq!(vertex_map.len(), 1);
    }
}
