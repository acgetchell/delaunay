name: Performance Regression Testing

# Run performance regression testing on important changes
on:
  # Manual trigger
  workflow_dispatch:

  # Pull requests to main branch
  pull_request:
    branches:
      - main
    # Only run on changes that could affect performance
    paths:
      - 'src/**'
      - 'benches/**'
      - 'Cargo.toml'
      - 'Cargo.lock'

  # On pushes to main branch
  push:
    branches:
      - main
    # Only run on changes that could affect performance
    paths:
      - 'src/**'
      - 'benches/**'
      - 'Cargo.toml'
      - 'Cargo.lock'

# Security: Define minimal required permissions
permissions:
  contents: read
  actions: read
  pull-requests: read

concurrency:
  group: perf-regress-${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1

jobs:
  performance-regression:
    runs-on: macos-15
    timeout-minutes: 45

    steps:
      - uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8  # v5.0.0
        with:
          fetch-depth: 0  # required to diff against BASELINE_COMMIT

      - name: Install Rust toolchain
        uses: actions-rust-lang/setup-rust-toolchain@ac90e63697ac2784f4ecfe2964e1a285c304003a  # v1.14.1
        with:
          cache: true
          # Toolchain from rust-toolchain.toml; no extra target needed on macOS-ARM

      - name: Install uv (Python package manager)
        uses: astral-sh/setup-uv@557e51de59eb14aaaba2ed9621916900a91d50c6  # v6.6.1
        with:
          version: "latest"

      - name: Verify uv installation
        run: uv --version

      - name: Install jq (required for baseline generation fallback)
        run: |
          # macOS runner should have jq, but ensure it's available
          if ! command -v jq >/dev/null 2>&1; then
            echo "Installing jq..."
            brew install jq
          else
            echo "jq is already available: $(jq --version)"
          fi

      - name: Find latest release with baseline artifact
        id: find_baseline
        uses: actions/github-script@60a0d83039c74a4aee543508d2ffcb1c3799cdea  # v7.0.1
        with:
          script: |
            try {
              // Get all releases, sorted by creation date (newest first)
              const releases = await github.rest.repos.listReleases({
                owner: context.repo.owner,
                repo: context.repo.repo,
                per_page: 100
              });

              console.log(`Found ${releases.data.length} releases`);

              // Look for releases with baseline artifacts
              for (const release of releases.data) {
                console.log(`Checking release ${release.tag_name}...`);

                // List recent runs and look for an artifact matching the release tag
                try {
                  const runs = await github.rest.actions.listWorkflowRuns({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    workflow_id: 'generate-baseline.yml',
                    status: 'completed',
                    conclusion: 'success',
                    per_page: 10
                  });
                  const expectedName = `performance-baseline-${release.tag_name}`;
                  for (const run of runs.data.workflow_runs) {
                    const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
                      owner: context.repo.owner,
                      repo: context.repo.repo,
                      run_id: run.id
                    });
                    const baselineArtifact = artifacts.data.artifacts.find(a => a.name === expectedName);
                    if (baselineArtifact) {
                      console.log(
                        `Found baseline artifact ${expectedName} in run ${run.id} ` +
                        `for release ${release.tag_name}`
                      );
                      core.setOutput('found', 'true');
                      core.setOutput('release_tag', release.tag_name);
                      core.setOutput('artifact_name', expectedName);
                      core.setOutput('run_id', run.id.toString());
                      return;
                    }
                  }
                } catch (error) {
                  console.log(`Error checking release ${release.tag_name}: ${error.message}`);
                  continue;
                }
              }

              console.log('No baseline artifacts found in any release');
              core.setOutput('found', 'false');
            } catch (error) {
              console.error(`Error searching for baseline artifacts: ${error.message}`);
              core.setOutput('found', 'false');
            }

      - name: Download latest baseline artifact
        if: steps.find_baseline.outputs.found == 'true'
        uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0  # v5.0.0
        with:
          name: ${{ steps.find_baseline.outputs.artifact_name }}
          path: baseline-artifact/
          run-id: ${{ steps.find_baseline.outputs.run_id }}
          github-token: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract baseline from artifact
        if: steps.find_baseline.outputs.found == 'true'
        shell: bash
        run: |
          set -euo pipefail
          if [[ -f "baseline-artifact/baseline_results.txt" ]]; then
            echo "üì¶ Extracted baseline from artifact for release ${{ steps.find_baseline.outputs.release_tag }}"
            cp "baseline-artifact/baseline_results.txt" "benches/baseline_results.txt"

            echo "BASELINE_EXISTS=true" >> "$GITHUB_ENV"
            echo "BASELINE_SOURCE=artifact" >> "$GITHUB_ENV"

            # Show baseline metadata
            echo "=== Baseline Information (from artifact) ==="
            head -n 3 benches/baseline_results.txt
          else
            echo "‚ùå Downloaded artifact but no baseline_results.txt found"
            echo "BASELINE_EXISTS=false" >> "$GITHUB_ENV"
            echo "BASELINE_SOURCE=missing" >> "$GITHUB_ENV"
          fi

      - name: Generate fallback baseline if none found
        if: steps.find_baseline.outputs.found != 'true'
        shell: bash
        run: |
          set -euo pipefail
          echo "üìà No baseline artifact found, generating fallback baseline..."
          echo "   This baseline will be used for this comparison only."
          echo ""

          # Generate baseline using dev mode for faster execution
          if uv run benchmark-utils generate-baseline --dev; then
            echo "BASELINE_EXISTS=true" >> "$GITHUB_ENV"
            echo "BASELINE_SOURCE=generated" >> "$GITHUB_ENV"

            echo "‚úÖ Generated fallback baseline successfully"
            echo "=== Generated Baseline Information ==="
            head -n 3 benches/baseline_results.txt
          else
            echo "‚ùå Failed to generate fallback baseline"
            echo "BASELINE_EXISTS=false" >> "$GITHUB_ENV"
            echo "BASELINE_SOURCE=failed" >> "$GITHUB_ENV"
          fi

      - name: Extract baseline commit SHA
        if: env.BASELINE_EXISTS == 'true'
        shell: bash
        run: |
          set -euo pipefail
          bc_sha="$(grep "^Git commit:" benches/baseline_results.txt | awk '{print $3}' || true)"
          if [[ -n "$bc_sha" && "$bc_sha" =~ ^[0-9a-f]{7,40}$ ]]; then
            echo "BASELINE_COMMIT=$bc_sha" >> "$GITHUB_ENV"
          else
            echo "BASELINE_COMMIT=unknown" >> "$GITHUB_ENV"
          fi

      - name: Determine if benchmarks should run
        if: env.BASELINE_EXISTS == 'true'
        shell: bash
        env:
          CURRENT_SHA: ${{ github.sha }}
        run: |
          set -euo pipefail
          if [[ "$BASELINE_COMMIT" == "unknown" ]]; then
            echo "SKIP_BENCHMARKS=false" >> "$GITHUB_ENV"
          elif [[ "$BASELINE_COMMIT" == "$CURRENT_SHA" ]]; then
            echo "SKIP_BENCHMARKS=true" >> "$GITHUB_ENV"
          else
            if git diff --name-only "$BASELINE_COMMIT"... | grep -qE '^(src/|benches/|Cargo\.toml|Cargo\.lock)'; then
              echo "SKIP_BENCHMARKS=false" >> "$GITHUB_ENV"
            else
              echo "SKIP_BENCHMARKS=true" >> "$GITHUB_ENV"
            fi
          fi

      - name: Skip benchmarks - no code changes
        if: env.BASELINE_EXISTS == 'true' && env.SKIP_BENCHMARKS == 'true'
        shell: bash
        run: |
          set -euo pipefail
          echo "üîç Current commit matches baseline (${BASELINE_COMMIT}), skipping benchmarks."

      - name: Skip benchmarks - no baseline available
        if: env.BASELINE_EXISTS != 'true'
        shell: bash
        run: |
          set -euo pipefail
          echo "‚ö†Ô∏è No performance baseline available for comparison."
          if [[ "${BASELINE_SOURCE:-}" == "failed" ]]; then
            echo "   - Failed to generate fallback baseline"
            echo "   - Check the baseline generation workflow logs for issues"
          else
            echo "   - No baseline artifacts found in recent releases"
            echo "   - Create a new release tag to generate a baseline"
          fi
          echo ""
          echo "üí° To resolve:"
          echo "   1. Create a new release tag (e.g., v0.4.2)"
          echo "   2. The baseline generation workflow will run automatically"
          echo "   3. Future PRs and pushes will use that baseline for comparison"

      - name: Run performance regression test
        if: env.BASELINE_EXISTS == 'true' && env.SKIP_BENCHMARKS == 'false'
        shell: bash
        run: |
          set -euo pipefail
          echo "üöÄ Running performance regression test..."
          echo "   Baseline source: ${BASELINE_SOURCE:-unknown}"

          # This will exit with code 1 if significant regressions are found
          uv run benchmark-utils compare --baseline benches/baseline_results.txt

      - name: Display regression test results
        if: env.BASELINE_EXISTS == 'true' && env.SKIP_BENCHMARKS == 'false' && always()
        shell: bash
        run: |
          set -euo pipefail
          if [[ -f "benches/compare_results.txt" ]]; then
            echo "=== Performance Regression Test Results ==="
            cat benches/compare_results.txt
          else
            echo "‚ö†Ô∏è No comparison results file found"
          fi

      - name: Upload regression test results
        if: env.BASELINE_EXISTS == 'true' && env.SKIP_BENCHMARKS == 'false' && always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02  # v4.6.2
        with:
          name: performance-regression-results-${{ github.run_number }}
          path: benches/compare_results.txt
          retention-days: 30

      - name: Summary
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          echo "üìä Performance Regression Testing Summary"
          echo "==========================================="
          echo "Baseline source: ${BASELINE_SOURCE:-none}"
          echo "Baseline exists: ${BASELINE_EXISTS:-false}"
          echo "Skip benchmarks: ${SKIP_BENCHMARKS:-unknown}"

          if [[ "${BASELINE_EXISTS:-false}" == "true" && "${SKIP_BENCHMARKS:-true}" == "false" ]]; then
            if [[ -f "benches/compare_results.txt" ]]; then
              if grep -q "REGRESSION" benches/compare_results.txt; then
                echo "Result: ‚ö†Ô∏è Performance regressions detected"
              else
                echo "Result: ‚úÖ No significant performance regressions"
              fi
            else
              echo "Result: ‚ùì Benchmark comparison completed but no results file found"
            fi
          elif [[ "${SKIP_BENCHMARKS:-true}" == "true" ]]; then
            echo "Result: ‚è≠Ô∏è Benchmarks skipped (no relevant code changes)"
          else
            echo "Result: ‚è≠Ô∏è Benchmarks skipped (no baseline available)"
          fi
