name: Performance Regression Testing

# Run performance regression testing on important changes
# Security: All GitHub context variables are passed through safe environment variables
# to prevent code injection attacks via malicious branch names or commit data
on:
  # Manual trigger
  workflow_dispatch:

  # Pull requests to main branch
  pull_request:
    branches:
      - main
    # Only run on changes that could affect performance
    paths:
      - "src/**"
      - "benches/**"
      - "Cargo.toml"
      - "Cargo.lock"

  # On pushes to main branch
  push:
    branches:
      - main
    # Only run on changes that could affect performance
    paths:
      - "src/**"
      - "benches/**"
      - "Cargo.toml"
      - "Cargo.lock"

# Security: Define minimal required permissions
permissions:
  contents: read
  actions: read
  pull-requests: read

concurrency:
  group: perf-regress-${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1
  BENCHMARK_TIMEOUT: 5400 # 90 minutes for CI benchmarks (4D/5D triangulations are expensive)

jobs:
  performance-regression:
    runs-on: macos-15
    timeout-minutes: 105 # Allow 90min benchmark timeout + 15min for setup/teardown

    steps:
      - uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
        with:
          fetch-depth: 0 # required to diff against BASELINE_COMMIT

      - name: Install Rust toolchain
        uses: actions-rust-lang/setup-rust-toolchain@1780873c7b576612439a134613cc4cc74ce5538c # v1.15.2
        with:
          cache: true
          # Toolchain from rust-toolchain.toml; no extra target needed on macOS-ARM

      - name: Install uv (Python package manager)
        uses: astral-sh/setup-uv@681c641aba71e4a1c380be3ab5e12ad51f415867 # v7.1.6
        with:
          version: "latest"

      - name: Verify uv installation
        run: uv --version

      - name: Find baseline artifact
        id: find_baseline
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          script: |
            try {
              // Precompute expected baseline names for early-hit optimization
              const releases = await github.paginate(
                github.rest.repos.listReleases,
                { owner: context.repo.owner, repo: context.repo.repo, per_page: 50 }
              );

              const expectedReleaseBaselines = new Set();
              for (const release of releases) {
                if (!release.draft && !release.prerelease) {
                  const cleanTag = release.tag_name.replace(/[^a-zA-Z0-9._-]/g, '_');
                  expectedReleaseBaselines.add(`performance-baseline-${cleanTag}`);
                }
              }
              console.log(`Precomputed ${expectedReleaseBaselines.size} expected release baseline names`);

              // Fetch all successful generate-baseline.yml runs once (O(runs) API calls)
              console.log('Fetching recent generate-baseline.yml runs...');
              let count = 0;
              const runs = await github.paginate(
                github.rest.actions.listWorkflowRuns,
                {
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  workflow_id: 'generate-baseline.yml',
                  status: 'completed',
                  conclusion: 'success',
                  per_page: 100
                },
                (response, done) => {
                  // Limit to 150 runs total across pages (no overshoot)
                  const remaining = Math.max(0, 150 - count);
                  if (remaining === 0) { done(); return []; }
                  const slice = response.data.slice(0, remaining);
                  count += slice.length;
                  if (count >= 150) done();
                  return slice;
                }
              );

              console.log(`Found ${runs.length} successful generate-baseline runs`);

              // Build artifact cache: artifact name â†’ {run_id, run_created_at}
              const artifactCache = new Map();
              let foundReleaseBaseline = false;
              for (const run of runs) {
                try {
                  const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    run_id: run.id
                  });

                  for (const artifact of artifacts.data.artifacts) {
                    if (artifact.name.startsWith('performance-baseline-') && artifact.expired !== true) {
                      if (!artifactCache.has(artifact.name)) {
                        artifactCache.set(artifact.name, {
                          run_id: run.id,
                          run_created_at: run.created_at
                        });

                        // Early-hit optimization: stop if we found a release baseline
                        if (expectedReleaseBaselines.has(artifact.name)) {
                          console.log(`Early hit: found release baseline ${artifact.name}, stopping search`);
                          foundReleaseBaseline = true;
                        }
                      }
                    }
                  }

                  // Short-circuit if we found a release baseline
                  if (foundReleaseBaseline) break;
                } catch (error) {
                  console.log(`Warning: Could not fetch artifacts for run ${run.id}: ${error.message}`);
                  continue;
                }
              }

              console.log(`Built cache of ${artifactCache.size} baseline artifacts`);

              console.log(`Found ${releases.length} releases (already fetched)`);

              // Look for releases with baseline artifacts (now O(releases) lookups)
              for (const release of releases) {
                console.log(`Checking release ${release.tag_name}...`);
                if (release.draft || release.prerelease) {
                  console.log(`Skipping draft/prerelease ${release.tag_name}`);
                  continue;
                }

                // Must match sanitize step in .github/workflows/generate-baseline.yml
                const cleanTag = release.tag_name.replace(/[^a-zA-Z0-9._-]/g, '_');
                const expectedName = `performance-baseline-${cleanTag}`;

                if (artifactCache.has(expectedName)) {
                  const artifactInfo = artifactCache.get(expectedName);
                  console.log(
                    `Found release baseline artifact ${expectedName} in run ${artifactInfo.run_id} ` +
                    `for release ${release.tag_name}`
                  );
                  core.setOutput('found', 'true');
                  core.setOutput('release_tag', release.tag_name);
                  core.setOutput('artifact_name', expectedName);
                  core.setOutput('run_id', artifactInfo.run_id.toString());
                  core.setOutput('source_type', 'release');
                  return;
                }
              }

              console.log('No release baseline artifacts found, checking for any recent baselines...');

              // Fallback: look for any recent baseline artifact (including manual runs)
              if (artifactCache.size > 0) {
                // Find the most recent artifact (by run creation time)
                let mostRecentArtifact = null;
                let mostRecentTime = null;

                for (const [artifactName, artifactInfo] of artifactCache.entries()) {
                  const runTime = new Date(artifactInfo.run_created_at);
                  if (!mostRecentTime || runTime > mostRecentTime) {
                    mostRecentTime = runTime;
                    mostRecentArtifact = { name: artifactName, ...artifactInfo };
                  }
                }

                if (mostRecentArtifact) {
                  console.log(
                    `Found baseline artifact ${mostRecentArtifact.name} in run ${mostRecentArtifact.run_id} ` +
                    `(created: ${mostRecentArtifact.run_created_at})`
                  );
                  core.setOutput('found', 'true');
                  core.setOutput('release_tag', 'manual-baseline');
                  core.setOutput('artifact_name', mostRecentArtifact.name);
                  core.setOutput('run_id', mostRecentArtifact.run_id.toString());
                  core.setOutput('source_type', 'manual');
                  return;
                }
              }

              console.log('No baseline artifacts found in any recent runs');
              core.setOutput('found', 'false');
            } catch (error) {
              console.error(`Error searching for baseline artifacts: ${error.message}`);
              core.setOutput('found', 'false');
            }

      - name: Download latest baseline artifact
        if: steps.find_baseline.outputs.found == 'true'
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        continue-on-error: true
        with:
          name: ${{ steps.find_baseline.outputs.artifact_name }}
          path: baseline-artifact/
          run-id: ${{ steps.find_baseline.outputs.run_id }}
          github-token: ${{ secrets.GITHUB_TOKEN }}

      - name: Prepare baseline for comparison
        if: steps.find_baseline.outputs.found == 'true'
        env:
          RELEASE_TAG: ${{ steps.find_baseline.outputs.release_tag }}
          SOURCE_TYPE: ${{ steps.find_baseline.outputs.source_type }}
        run: |
          # Set additional environment variables based on source
          echo "BASELINE_ORIGIN=${SOURCE_TYPE:-unknown}" >> "$GITHUB_ENV"
          if [[ -n "${RELEASE_TAG:-}" ]]; then
            echo "BASELINE_TAG=${RELEASE_TAG}" >> "$GITHUB_ENV"
          fi

          # Prepare baseline using Python utility
          uv run benchmark-utils prepare-baseline

      - name: Set baseline status if none found
        if: steps.find_baseline.outputs.found != 'true'
        run: uv run benchmark-utils set-no-baseline

      - name: Extract baseline commit SHA
        if: env.BASELINE_EXISTS == 'true'
        run: uv run benchmark-utils extract-baseline-commit

      - name: Determine if benchmarks should run
        if: env.BASELINE_EXISTS == 'true'
        env:
          SAFE_COMMIT_SHA: ${{ github.sha }}
        run: |
          uv run benchmark-utils determine-skip \
            --baseline-commit "$BASELINE_COMMIT" \
            --current-commit "$SAFE_COMMIT_SHA"

      - name: Skip benchmarks - no code changes
        if: env.BASELINE_EXISTS == 'true' && env.SKIP_BENCHMARKS == 'true'
        run: |
          uv run benchmark-utils display-skip-message \
            --reason "$SKIP_REASON" \
            --baseline-commit "$BASELINE_COMMIT"

      - name: Skip benchmarks - no baseline available
        if: env.BASELINE_EXISTS != 'true'
        run: uv run benchmark-utils display-no-baseline

      - name: Run performance regression test (same-runner A/B)
        if: env.BASELINE_EXISTS == 'true' && env.SKIP_BENCHMARKS == 'false'
        env:
          SAFE_COMMIT_SHA: ${{ github.sha }}
        run: |
          set -euo pipefail

          echo "   Baseline origin: ${BASELINE_ORIGIN:-unknown}"
          echo "   Baseline commit: ${BASELINE_COMMIT:-}"
          echo "   Current commit:  ${SAFE_COMMIT_SHA:-}"

          # Security: validate SHAs before using in git commands
          if [[ ! "${BASELINE_COMMIT:-}" =~ ^[0-9A-Fa-f]{7,40}$ ]]; then
            echo "Invalid BASELINE_COMMIT: ${BASELINE_COMMIT:-}" >&2
            exit 1
          fi
          if [[ ! "${SAFE_COMMIT_SHA:-}" =~ ^[0-9A-Fa-f]{7,40}$ ]]; then
            echo "Invalid SAFE_COMMIT_SHA: ${SAFE_COMMIT_SHA:-}" >&2
            exit 1
          fi

          # Always return to the current commit so follow-on steps run with current scripts.
          cleanup() {
            git checkout --force "${SAFE_COMMIT_SHA}" >/dev/null 2>&1 || true
          }
          trap cleanup EXIT

          # Generate an on-runner baseline at BASELINE_COMMIT, then compare at SAFE_COMMIT_SHA.
          # This avoids cross-runner/cross-day noise on GitHub-hosted macOS runners.
          mkdir -p ab-baseline
          rm -f ab-baseline/baseline_results.txt

          # Preserve the benchmark harness so BASELINE_COMMIT and SAFE_COMMIT_SHA
          # are measured with identical benchmark code.
          cp benches/ci_performance_suite.rs ab-baseline/ci_performance_suite.rs

          echo "=== Baseline benchmark (same runner) ==="
          git checkout --force "${BASELINE_COMMIT}"
          cp ab-baseline/ci_performance_suite.rs benches/ci_performance_suite.rs
          uv run benchmark-utils generate-baseline \
            --output "ab-baseline/baseline_results.txt" \
            --bench-timeout "${BENCHMARK_TIMEOUT}" \
            --dev

          echo "=== Current benchmark + compare ==="
          git checkout --force "${SAFE_COMMIT_SHA}"
          uv run benchmark-utils compare \
            --baseline "ab-baseline/baseline_results.txt" \
            --bench-timeout "${BENCHMARK_TIMEOUT}" \
            --dev

      - name: Display regression test results
        if: env.BASELINE_EXISTS == 'true' && env.SKIP_BENCHMARKS == 'false' && always()
        run: uv run benchmark-utils display-results

      - name: Upload regression test results
        if: env.BASELINE_EXISTS == 'true' && env.SKIP_BENCHMARKS == 'false' && always()
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: performance-regression-results-${{ github.run_number }}
          path: |
            benches/compare_results.txt
            ab-baseline/baseline_results.txt
            ab-baseline/ci_performance_suite.rs
          if-no-files-found: warn
          retention-days: 30

      - name: Summary
        if: always()
        run: uv run benchmark-utils regression-summary
