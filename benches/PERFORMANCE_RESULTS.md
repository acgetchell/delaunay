# Delaunay Library Performance Results

This file contains performance benchmarks and analysis for the delaunay library.
The results are automatically generated and updated by the benchmark infrastructure.

**Last Updated**: 2025-12-07 01:47:57 UTC
**Generated By**: benchmark_utils.py
**Git Commit**: eef1763475b609c673e61d9a4e880669a1ad921a
**Hardware**: Apple M4 Max (16 cores)
**Memory**: 64.0 GB
**OS**: macOS
**Rust**: rustc 1.91.0 (f8297e351 2025-10-28)

## Performance Results Summary

### Circumsphere Performance Results

#### Version 0.6.0 Results (2025-12-06)

#### Single Query Performance (2D)

| Test Case | insphere | insphere_distance | insphere_lifted | Winner |
|-----------|----------|------------------|-----------------|---------|
| Basic 2D | 110 ns | 78 ns | 44 ns | **insphere_lifted** |
| Boundary vertex | 3 ns | 78 ns | 41 ns | **insphere** |
| Far vertex | 101 ns | 79 ns | 41 ns | **insphere_lifted** |

#### Single Query Performance (3D)

| Test Case | insphere | insphere_distance | insphere_lifted | Winner |
|-----------|----------|------------------|-----------------|---------|
| Basic 3D | 206 ns | 94 ns | 164 ns | **insphere_distance** |
| Boundary vertex | 4 ns | 95 ns | 163 ns | **insphere** |
| Far vertex | 203 ns | 95 ns | 165 ns | **insphere_distance** |

#### Single Query Performance (4D)

| Test Case | insphere | insphere_distance | insphere_lifted | Winner |
|-----------|----------|------------------|-----------------|---------|
| Basic 4D | 277 ns | 170 ns | 222 ns | **insphere_distance** |
| Boundary vertex | 4 ns | 172 ns | 225 ns | **insphere** |
| Far vertex | 286 ns | 172 ns | 229 ns | **insphere_distance** |

#### Single Query Performance (5D)

| Test Case | insphere | insphere_distance | insphere_lifted | Winner |
|-----------|----------|------------------|-----------------|---------|
| Basic 5D | 354 ns | 352 ns | 295 ns | **insphere_lifted** |
| Boundary vertex | 4 ns | 355 ns | 290 ns | **insphere** |
| Far vertex | 360 ns | 358 ns | 293 ns | **insphere_lifted** |

## Key Findings

### Performance Ranking

1. **insphere_distance** - (best in 3D, 4D) - Best average performance
2. **insphere_lifted** - (best in 2D, 5D) - ~1.0x average vs fastest
3. **insphere** - ~1.4x slower than fastest on average

### Numerical Accuracy Analysis

Based on random test cases:

- **insphere vs insphere_distance**: ~82% agreement (reference data)
- **insphere vs insphere_lifted**: ~0% agreement (different algorithms, reference data)
- **insphere_distance vs insphere_lifted**: ~18% agreement (reference data)
- **All three methods agree**: ~0% (expected due to different numerical approaches, reference data)

*Note: To get current numerical accuracy data, run with `--run-benchmarks` flag.*

## Recommendations

### Method Selection Guide

**All three methods produce correct results with 100% agreement.**
Choose based on your specific requirements:

#### Performance Optimization by Dimension

- **`insphere_distance`**: (best in 3D, 4D) - Best average performance
- **`insphere_lifted`**: (best in 2D, 5D) - ~1.0x average vs fastest

#### General Recommendations

**For maximum performance**: Choose the method that performs best in your target dimension (see above)

**For general-purpose use**: `insphere` provides consistent performance across all dimensions
and uses the standard determinant-based approach with well-understood numerical properties

**For algorithm transparency**: `insphere_distance` explicitly calculates the circumcenter,
making it excellent for educational purposes, debugging, and algorithm validation

#### Performance Comparison

Average performance across all non-boundary test cases:

- `insphere_distance`: 175 ns (fastest average)
- `insphere_lifted`: 182 ns (close second)
- `insphere`: 237 ns (consistent across dimensions)


## Conclusion

All three methods achieve 100% agreement on correctness. Performance characteristics vary by dimension:

- `insphere_distance` (best in 3D, 4D) - Best average performance
- `insphere_lifted` (best in 2D, 5D) - ~1.0x average vs fastest

For general-purpose applications, choose based on your primary use case:

- **Performance-critical**: Use the method that performs best in your target dimension
- **Numerical stability**: Use `insphere` for its proven mathematical properties
- **Educational/debugging**: Use `insphere_distance` for its transparent algorithm

## Historical Version Comparison

*Based on archived performance measurements from previous releases:*

### v0.3.0 → v0.3.1 Performance Improvements

| Test Case | Method | v0.3.0 | v0.3.1 | Improvement |
|-----------|--------|--------|--------|-------------|
| Basic 3D | insphere | 808 ns | 805 ns | +0.4% |
| Basic 3D | insphere_distance | 1,505 ns | 1,463 ns | +2.8% |
| Basic 3D | insphere_lifted | 646 ns | 637 ns | +1.4% |
| Random 1000 queries | insphere | 822 µs | 811 µs | +1.3% |
| Random 1000 queries | insphere_distance | 1,535 µs | 1,494 µs | +2.7% |
| Random 1000 queries | insphere_lifted | 661 µs | 650 µs | +1.7% |
| 2D | insphere_lifted | 442 ns | 440 ns | +0.5% |
| 4D | insphere_lifted | 962 ns | 955 ns | +0.7% |

**Key Improvements**: Version 0.3.1 showed consistent performance gains across all methods,
with `insphere_distance` seeing the largest improvement (+2.8%). The changes implemented
improved numerical stability using `hypot` and `squared_norm` functions while providing
measurable performance gains.

## Implementation Notes

### Performance Advantages of `insphere_lifted`

1. More efficient matrix formulation using relative coordinates
2. Avoids redundant circumcenter calculations
3. Optimized determinant computation

### Method Disagreements

The disagreements between methods are expected due to:

1. Different numerical approaches and tolerances
2. Floating-point precision differences in multi-step calculations
3. Varying sensitivity to degenerate cases

## Benchmark Structure

The `circumsphere_containment.rs` benchmark includes:

- **Random queries**: Batch processing performance with 1000 random test points
- **Dimensional tests**: Performance across 2D, 3D, 4D, and 5D simplices
- **Edge cases**: Boundary vertices and far-away points
- **Numerical consistency**: Agreement analysis between all methods

## Performance Data Updates

This file is automatically generated from benchmark results. To update:

```bash
# Generate performance summary with current data
uv run benchmark-utils generate-summary

# Run fresh benchmarks and generate summary (includes numerical accuracy)
uv run benchmark-utils generate-summary --run-benchmarks

# Generate baseline results for regression testing
uv run benchmark-utils generate-baseline
```

### Customization

For manual updates or custom analysis, modify the `PerformanceSummaryGenerator`
class in `scripts/benchmark_utils.py`. This provides enhanced control over
dynamic vs static content organization and supports parsing numerical accuracy
data from live benchmark runs.
